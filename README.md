<p align="center">
   <img src="https://github.com/AishaEvering/FacialEmotionDetection/blob/main/emotion.png" alt="Emotion Detection">
</p>

# Emotion Detection

This project serves as an capstone endeavor undertaken to advance towards achieving my MIT Applied Data Science certification.

## Technologies
[![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)](https://matplotlib.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/stable/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)](https://www.tensorflow.org/)
[![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)](https://jupyter.org/)

## üìÉOverview

In this project, I aimed to develop a multi-class classification model to detect emotions-sad, happy, surprised, and neutral-from facial images.  The primary goal was to create an accurate model that can reliably classify emotions baseed on visual input.

## üè´ Learning Outcomes

1. **Impact of Transfer Learning**: Retraining 

1. **Impact of Transfer Learning:** Retraining models for transfer learning significantly improved performance. Although I observed promising results using VGG16, time constraints led me to pause further experiments. Nevertheless, this experience reinforced the value of transfer learning in enhancing model accuracy.
2. **No Guarantees with Transfer Learning:** Despite its advantages, transfer learning does not automatically ensure high accuracy. Each model and dataset require careful tuning and evaluation.
3. **Grayscale vs RGB:** Using grayscale images versus RGB images did not result in substantial differences in model performance.
4. **Importance of Data Augmentation:** Although exploratory data analysis (EDA) was limited for the convolutional neural networks (CNNs), augmenting and flipping images proved effective in improving accuracy.

## üîë Key Takeaways

* CNN vs Transfer Learning: In this particular case, a basic CNN model outperformed transfer learning approaches. This highlights that, while advanced techniques like transfer learning can be beneficial, simpler models can sometimes yield better results depending on the context.


### üò§ Challenges Faced

* **Ineffective Transfer Learning with EfficientNet**: I encountered difficulties using the EfficientNet model for transfer learning, as it did not produce satisfactory results. This experience underscored the complexity and challenges of selecting and tuning pre-trained models for specific tasks.

### ‚òëÔ∏è Next Steps

* **Present Findings:** Share detailed insights and results from this project.
* **Certification:** Obtain my MIT Applied Data Science Certificate to further validate and enhance my expertise.
  
### üìñ Dataset Details

* **Training Data:** 15,109 images
* **Testing Data:** 128 images
* **Validation Data:** 4,977 images
* **Location:** All data is available on my Google Drive.

  
## Author

Aisha Evering  
[Email](<shovon3000g@gmail.com>) | [Portfolio](https://aishaeportfolio.com/)

